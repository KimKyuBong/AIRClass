<script>
  import { onMount, onDestroy, tick } from 'svelte';
  
  let ws = null;
  let videoElement = null;
  let pc = null; // WebRTC PeerConnection
  let isConnected = false;
  let isVideoLoaded = false;
  let messages = [];
  let newMessage = '';
  let studentName = '';
  let isJoined = false;
  let streamToken = '';
  let webrtcUrl = '';
  let latencyMonitorInterval = null;
  let currentLatency = 0;
  let nodeInfo = null; // ì—°ê²°ëœ ë…¸ë“œ ì •ë³´
  let isPortraitVideo = false; // ì„¸ë¡œ ëª¨ë“œ ì˜ìƒ ì—¬ë¶€
  let videoContainerClass = ''; // ë™ì  ì»¨í…Œì´ë„ˆ í´ë˜ìŠ¤
  
  // Reactive: isPortraitVideo ë³€ê²½ ì‹œ videoContainerClass ìë™ ì—…ë°ì´íŠ¸
  $: videoContainerClass = isPortraitVideo ? 'portrait-video' : 'landscape-video';

  onMount(async () => {
    console.log('[Student] Component mounted');
    
    // URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì—ì„œ name ê°€ì ¸ì˜¤ê¸°
    const urlParams = new URLSearchParams(window.location.search);
    const nameFromUrl = urlParams.get('name');
    
    console.log('[Student] Name from URL:', nameFromUrl);
    
    if (nameFromUrl) {
      // URLì— nameì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì°¸ì—¬
      studentName = nameFromUrl;
      console.log('[Student] Auto-joining with name:', studentName);
      await joinClass();
    } else {
      // URLì— nameì´ ì—†ìœ¼ë©´ localStorageì—ì„œ ê°€ì ¸ì˜¤ê¸°
      studentName = localStorage.getItem('studentName') || '';
      console.log('[Student] Name from localStorage:', studentName);
    }
  });

  onDestroy(() => {
    if (pc) {
      pc.close();
    }
    if (ws) {
      ws.close();
    }
    if (latencyMonitorInterval) {
      clearInterval(latencyMonitorInterval);
    }
  });

  async function joinClass() {
    if (!studentName.trim()) return;
    
    localStorage.setItem('studentName', studentName);
    
    console.log('[Student] Joining class as:', studentName);
    
    // 1. í† í° ë°œê¸‰ ë°›ê¸°
    try {
      const response = await fetch(`/api/token?user_type=student&user_id=${encodeURIComponent(studentName)}`, {
        method: 'POST'
      });
      const data = await response.json();
      streamToken = data.token;
      // ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° í˜„ì¬ origin ì¶”ê°€
      if (data.webrtc_url) {
        webrtcUrl = data.webrtc_url.startsWith('/') 
          ? window.location.origin + data.webrtc_url 
          : data.webrtc_url;
      } else {
        throw new Error('No webrtc_url in response');
      }
      
      // ë…¸ë“œ ì •ë³´ ì €ì¥
      nodeInfo = {
        mode: data.mode || 'unknown',
        node_name: data.node_name || 'unknown',
        node_id: data.node_id || 'unknown',
        host: data.host || window.location.hostname,
        webrtc_port: data.webrtc_url ? data.webrtc_url.split(':')[2]?.split('/')[0] : 'unknown'
      };
      
      console.log('[Student] Token received:', data);
      console.log('[Student] WebRTC URL:', webrtcUrl);
      console.log('[Student] Connected to node:', nodeInfo);
      
      // 2. Set joined state first to render the video element
      isJoined = true;
      
      // 3. Wait for DOM to update
      await tick();
      console.log('[Student] DOM updated, videoElement:', videoElement);
      
      // 4. Configure video element for ultra-low latency
      if (videoElement) {
        configureVideoForLowLatency(videoElement);
      }
      
      // 5. WebSocket ì—°ê²°
      connectWebSocket();
      
      // 6. WebRTC ì´ˆê¸°í™” (í† í° í¬í•¨)
      console.log('[Student] Initializing WebRTC...');
      initializeWebRTC(webrtcUrl);
      
    } catch (error) {
      alert('í† í° ë°œê¸‰ ì‹¤íŒ¨: ' + error.message);
      console.error('Token error:', error);
    }
  }

  /**
   * ë¸Œë¼ìš°ì € SDPë¥¼ MediaMTX í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   * MediaMTXëŠ” ì¼ë¶€ ë¸Œë¼ìš°ì € í™•ì¥ ì†ì„±ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°
   * curlë¡œ ì„±ê³µí•œ minimal SDP í˜•ì‹ì— ë§ì¶¤
   */
  function cleanSdpForMediaMTX(sdp) {
    const lines = sdp.split('\r\n');
    const cleaned = [];
    let hasIceLite = false;
    let hasSetup = false;
    let bundleGroup = null;
    
    for (let line of lines) {
      // ë¹ˆ ì¤„ì€ ìœ ì§€
      if (line.trim() === '') {
        cleaned.push(line);
        continue;
      }
      
      // í•„ìˆ˜ ì†ì„±ì€ ëª¨ë‘ ìœ ì§€: v=, o=, s=, t=, m=, c=, a=mid, a=recvonly, a=rtcp-mux
      // a=rtpmap, a=fmtp, a=ice-ufrag, a=ice-pwd, a=fingerprint
      
      // ì œê±°í•  í™•ì¥ ì†ì„±ë“¤
      const removePatterns = [
        /^a=extmap-allow-mixed/,     // í™•ì¥ ë§µ í˜¼í•© í—ˆìš©
        /^a=msid-semantic:/,         // MSID ì‹œë§¨í‹±
        /^a=extmap:/,                // í™•ì¥ ë§µ (ì¼ë¶€ëŠ” ìœ ì§€í•´ì•¼ í•  ìˆ˜ë„ ìˆìŒ)
      ];
      
      let shouldRemove = false;
      for (let pattern of removePatterns) {
        if (pattern.test(line)) {
          shouldRemove = true;
          break;
        }
      }
      
      // BUNDLE ê·¸ë£¹ì€ ì²« ë²ˆì§¸ë§Œ ìœ ì§€
      if (line.startsWith('a=group:BUNDLE')) {
        if (!bundleGroup) {
          bundleGroup = line;
          cleaned.push(line);
        }
        shouldRemove = true;
      }
      
      // ice-lite í™•ì¸ (ì„œë²„ê°€ ice-liteë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°)
      if (line.startsWith('a=ice-lite')) {
        hasIceLite = true;
      }
      
      // setup í™•ì¸
      if (line.startsWith('a=setup:')) {
        hasSetup = true;
        // setup:activeë¡œ ê°•ì œ ì„¤ì • (í´ë¼ì´ì–¸íŠ¸ëŠ” activeì—¬ì•¼ í•¨)
        if (!line.includes('active')) {
          line = 'a=setup:active';
        }
      }
      
      if (!shouldRemove) {
        cleaned.push(line);
      }
    }
    
    // setupì´ ì—†ìœ¼ë©´ ì¶”ê°€ (í´ë¼ì´ì–¸íŠ¸ëŠ” activeì—¬ì•¼ í•¨)
    if (!hasSetup) {
      // ë§ˆì§€ë§‰ m= ë¼ì¸ ë’¤ì— ì¶”ê°€
      for (let i = cleaned.length - 1; i >= 0; i--) {
        if (cleaned[i].startsWith('m=')) {
          cleaned.splice(i + 1, 0, 'a=setup:active');
          break;
        }
      }
    }
    
    // SDPë¥¼ ë‹¤ì‹œ ì¡°í•©
    let result = cleaned.join('\r\n');
    
    // ë§ˆì§€ë§‰ì— ë¹ˆ ì¤„ì´ ì—†ìœ¼ë©´ ì¶”ê°€ (í‘œì¤€ SDP í˜•ì‹)
    if (!result.endsWith('\r\n')) {
      result += '\r\n';
    }
    
    return result;
  }

  // Configure video element for ultra-low latency
  function configureVideoForLowLatency(video) {
    console.log('[Student] Configuring video for ultra-low latency');
    
    // Disable buffering for Firefox
    if (video.mozPreservesPitch !== undefined) {
      video.mozPreservesPitch = false;
    }
    
    // Force immediate playback without buffering
    video.addEventListener('loadedmetadata', () => {
      console.log('[Student] Video metadata loaded, forcing immediate playback');
      
      // ë¹„ë””ì˜¤ í¬ê¸° ê°ì§€ ë° aspect ratio ê³„ì‚°
      const videoWidth = video.videoWidth;
      const videoHeight = video.videoHeight;
      const aspectRatio = videoWidth / videoHeight;
      
      console.log('[Student] Video dimensions:', videoWidth, 'x', videoHeight, 'aspect ratio:', aspectRatio.toFixed(2));
      
      // ì„¸ë¡œ ëª¨ë“œ íŒë‹¨ (ë†’ì´ê°€ ë„ˆë¹„ë³´ë‹¤ í° ê²½ìš°)
      isPortraitVideo = videoHeight > videoWidth;
      
      if (isPortraitVideo) {
        console.log('[Student] ğŸ“± Portrait mode detected - using cover for full screen');
        videoContainerClass = 'portrait-video';
      } else {
        console.log('[Student] ğŸ–¥ï¸ Landscape mode detected - using contain');
        videoContainerClass = 'landscape-video';
      }
      
      video.play().catch(err => console.warn('[Student] Immediate play failed:', err.message));
    });
    
    // Monitor video lag and keep at live edge - AGGRESSIVE MODE
    latencyMonitorInterval = setInterval(() => {
      if (video.buffered.length > 0) {
        const currentTime = video.currentTime;
        const bufferedEnd = video.buffered.end(video.buffered.length - 1);
        const lag = bufferedEnd - currentTime;
        currentLatency = Math.round(lag * 1000); // Convert to ms
        
        // AGGRESSIVE: If lag exceeds 200ms, jump to live edge
        if (lag > 0.2) {
          console.warn('[Student] âš ï¸ Video lag detected:', lag.toFixed(3), 's - jumping to live edge');
          video.currentTime = bufferedEnd - 0.02; // Stay 20ms behind live edge
        }
        
        // ULTRA-AGGRESSIVE: If lag exceeds 500ms, something is wrong
        if (lag > 0.5) {
          console.error('[Student] ğŸ”´ CRITICAL LAG:', lag.toFixed(3), 's - forcing live edge');
          video.currentTime = bufferedEnd - 0.01; // Force to 10ms behind
        }
      }
    }, 50); // Check every 50ms (increased from 100ms) for faster response
  }

  async function initializeWebRTC(whepUrl, retryCount = 0) {
    console.log('[Student] initializeWebRTC called with URL:', whepUrl, 'retry:', retryCount);
    
    if (!videoElement) {
      console.error('[Student] videoElement not found! Retry count:', retryCount);
      
      // Retry up to 10 times with 200ms delay
      if (retryCount < 10) {
        setTimeout(() => initializeWebRTC(whepUrl, retryCount + 1), 200);
        return;
      } else {
        console.error('[Student] Failed to get videoElement after 10 retries');
        return;
      }
    }

    console.log('[Student] videoElement exists:', videoElement);
    console.log('[Student] Initializing WebRTC PeerConnection...');

    try {
      // Create RTCPeerConnection with ultra-low latency settings
      pc = new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' }
        ],
        // Optimize for lowest latency
        bundlePolicy: 'max-bundle',
        rtcpMuxPolicy: 'require',
        iceCandidatePoolSize: 0  // Don't pre-gather candidates
      });

      // Handle incoming tracks (video/audio from server)
      pc.ontrack = (event) => {
        console.log('[Student] ğŸ¥ Received track:', {
          kind: event.track.kind,
          id: event.track.id,
          readyState: event.track.readyState,
          muted: event.track.muted,
          enabled: event.track.enabled,
          streams: event.streams.length
        });
        
        event.track.onended = () => {
          console.log('[Student] âŒ Track ended:', event.track.kind);
        };
        
        event.track.onmute = () => {
          console.log('[Student] ğŸ”‡ Track muted:', event.track.kind);
        };
        
        event.track.onunmute = () => {
          console.log('[Student] ğŸ”Š Track unmuted:', event.track.kind);
          // Try to play when track unmutes
          if (videoElement && videoElement.srcObject) {
            console.log('[Student] ğŸ¬ Attempting playback after unmute...');
            videoElement.play().catch(err => console.warn('[Student] Playback attempt:', err.message));
          }
        };
        
        // Only set srcObject if we have a stream
        if (event.streams && event.streams.length > 0) {
          if (!videoElement.srcObject) {
            videoElement.srcObject = event.streams[0];
            console.log('[Student] âœ… Set video srcObject to stream, stream active:', event.streams[0].active);
            
            // Show video immediately when we get the first track
            isVideoLoaded = true;
            
            // Try to play immediately with aggressive retry
            setTimeout(() => {
              console.log('[Student] ğŸ¬ Attempting immediate playback...');
              videoElement.play()
                .then(() => {
                  console.log('[Student] â–¶ï¸ Video playback started successfully');
                })
                .catch(err => {
                  console.warn('[Student] âš ï¸ Playback failed:', err.message);
                  // Retry after a short delay
                  setTimeout(() => {
                    videoElement.play().catch(e => console.warn('[Student] Retry failed:', e.message));
                  }, 100);
                });
            }, 50); // Immediate attempt after 50ms
          }
          
          // Log stream tracks
          event.streams[0].getTracks().forEach(track => {
            console.log('[Student] Stream track:', {
              kind: track.kind,
              id: track.id,
              readyState: track.readyState,
              enabled: track.enabled,
              muted: track.muted
            });
          });
        }
      };

      // Handle ICE connection state changes
      pc.oniceconnectionstatechange = () => {
        console.log('[Student] ICE connection state:', pc.iceConnectionState);
        
        if (pc.iceConnectionState === 'connected' || pc.iceConnectionState === 'completed') {
          console.log('[Student] ğŸ‰ ICE connection established!');
          // Try to play when connection is established
          if (videoElement && videoElement.srcObject) {
            videoElement.play().catch(err => console.warn('[Student] Playback after ICE:', err.message));
          }
        }
        
        if (pc.iceConnectionState === 'failed' || pc.iceConnectionState === 'disconnected') {
          console.log('[Student] Connection failed, retrying in 3 seconds...');
          setTimeout(() => initializeWebRTC(whepUrl), 3000);
        }
      };

      // Handle ICE gathering state
      pc.onicegatheringstatechange = () => {
        console.log('[Student] ICE gathering state:', pc.iceGatheringState);
      };

      // Handle ICE candidates
      pc.onicecandidate = (event) => {
        if (event.candidate) {
          console.log('[Student] ICE candidate:', event.candidate.candidate);
        } else {
          console.log('[Student] ICE gathering complete');
        }
      };

      // Handle connection state
      pc.onconnectionstatechange = () => {
        console.log('[Student] Connection state:', pc.connectionState);
      };

      // Add transceiver to receive video with ultra-low latency settings
      const videoTransceiver = pc.addTransceiver('video', { 
        direction: 'recvonly'
      });
      const audioTransceiver = pc.addTransceiver('audio', { 
        direction: 'recvonly'
      });
      console.log('[Student] ğŸ“¡ Added transceivers - video:', videoTransceiver.mid, 'audio:', audioTransceiver.mid);

      // Create offer
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      console.log('[Student] Created offer, SDP length:', offer.sdp.length);
      console.log('[Student] SDP preview:', offer.sdp.substring(0, 500));
      
      // SDPë¥¼ MediaMTX í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
      const cleanedSdp = cleanSdpForMediaMTX(offer.sdp);
      console.log('[Student] Cleaned SDP length:', cleanedSdp.length);
      console.log('[Student] Cleaned SDP preview:', cleanedSdp.substring(0, 500));

      console.log('[Student] Sending cleaned offer to WHEP endpoint:', whepUrl);

      // Send offer to WHEP endpoint with JWT token
      const response = await fetch(whepUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/sdp',
          'Authorization': `Bearer ${streamToken}`
        },
        body: cleanedSdp
      });

      if (!response.ok) {
        throw new Error(`WHEP request failed: ${response.status} ${response.statusText}`);
      }

      // Get answer from server
      const answerSdp = await response.text();
      console.log('[Student] ğŸ“¥ Received answer from server, length:', answerSdp.length);
      console.log('[Student] Answer SDP preview:', answerSdp.substring(0, 200));
      // ë””ë²„ê¹…: ì„œë²„ ICE í›„ë³´(í¬íŠ¸) í™•ì¸
      const candLines = answerSdp.split('\r\n').filter(l => l.startsWith('a=candidate:') || l.startsWith('c='));
      if (candLines.length) console.log('[Student] Server ICE (c= / a=candidate):', candLines.slice(0, 10));

      await pc.setRemoteDescription({
        type: 'answer',
        sdp: answerSdp
      });

      console.log('[Student] âœ… WebRTC signaling complete! Waiting for ICE connection...');
      
      // Log current transceivers after remote description is set
      pc.getTransceivers().forEach((transceiver, index) => {
        console.log(`[Student] Transceiver ${index}:`, {
          mid: transceiver.mid,
          direction: transceiver.direction,
          currentDirection: transceiver.currentDirection,
          receiver: {
            track: transceiver.receiver.track ? {
              kind: transceiver.receiver.track.kind,
              id: transceiver.receiver.track.id,
              readyState: transceiver.receiver.track.readyState
            } : null
          }
        });
      });

    } catch (error) {
      console.error('[Student] WebRTC error:', error);
      if (retryCount < 5) {
        console.log('[Student] Retrying WebRTC connection in 3 seconds...');
        setTimeout(() => initializeWebRTC(whepUrl, retryCount + 1), 3000);
      } else {
        alert('WebRTC ì—°ê²° ì‹¤íŒ¨: ' + error.message);
      }
    }
  }

  function connectWebSocket() {
    ws = new WebSocket(`ws://${window.location.hostname}:8000/ws/student?name=${encodeURIComponent(studentName)}`);
    
    ws.onopen = () => {
      isConnected = true;
      console.log('Student WebSocket connected');
    };

    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      if (data.type === 'chat') {
        // ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬
        messages = [...messages, {
          sender: data.from,
          text: data.message
        }];
      }
    };

    ws.onclose = () => {
      isConnected = false;
      setTimeout(connectWebSocket, 3000);
    };
  }

  function sendMessage() {
    if (newMessage.trim() && ws) {
      ws.send(JSON.stringify({
        type: 'chat',
        message: newMessage
      }));
      newMessage = '';
    }
  }

  function leaveClass() {
    if (ws) ws.close();
    if (pc) pc.close();
    if (latencyMonitorInterval) clearInterval(latencyMonitorInterval);
    isJoined = false;
    isConnected = false;
    isVideoLoaded = false;
  }
</script>

<style>
  /* ê¸°ë³¸ ë¹„ë””ì˜¤ ìŠ¤íƒ€ì¼ */
  .video-stream {
    width: 100%;
    height: 100%;
    object-fit: contain;
  }

  /* ê°€ë¡œ ëª¨ë“œ ë¹„ë””ì˜¤ (ê¸°ë³¸) */
  .landscape-video .video-stream {
    object-fit: contain; /* ì „ì²´ë¥¼ ë³´ì—¬ì£¼ë©° ë¹„ìœ¨ ìœ ì§€ */
  }

  /* ì„¸ë¡œ ëª¨ë“œ ë¹„ë””ì˜¤ - í™”ë©´ì— ê½‰ ì°¨ê²Œ */
  .portrait-video {
    display: flex;
    align-items: center;
    justify-content: center;
  }

  .portrait-video .video-stream {
    width: auto !important;
    height: 100% !important;
    max-width: 100%;
    object-fit: cover; /* í™”ë©´ì„ ê½‰ ì±„ì›€ */
  }

  /* ë°˜ì‘í˜•: ì‘ì€ í™”ë©´ì—ì„œëŠ” ì„¸ë¡œ ì˜ìƒì´ ë„ˆë¹„ì— ë§ì¶°ì§€ë„ë¡ */
  @media (max-width: 768px) {
    .portrait-video .video-stream {
      width: 100% !important;
      height: auto !important;
      max-height: 100%;
    }
  }
</style>

{#if !isJoined}
  <!-- Join Screen -->
  <div class="min-h-screen bg-gradient-to-br from-blue-500 to-purple-600 flex items-center justify-center p-6">
    <div class="bg-white rounded-2xl shadow-2xl p-8 max-w-md w-full">
      <div class="text-center mb-8">
        <div class="text-6xl mb-4">ğŸ“</div>
        <h1 class="text-3xl font-bold text-gray-800 mb-2">AIRClass</h1>
        <p class="text-gray-600">ìˆ˜ì—…ì— ì°¸ì—¬í•˜ì„¸ìš”</p>
      </div>

      <form on:submit|preventDefault={joinClass} class="space-y-4">
        <div>
          <label class="block text-sm font-medium text-gray-700 mb-2">
            ì´ë¦„
          </label>
          <input
            type="text"
            bind:value={studentName}
            placeholder="ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
            class="w-full px-4 py-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
            required
          />
        </div>

        <button
          type="submit"
          class="w-full bg-blue-600 text-white py-3 rounded-lg font-semibold hover:bg-blue-700 transition"
        >
          ìˆ˜ì—… ì°¸ì—¬í•˜ê¸°
        </button>
      </form>
    </div>
  </div>
{:else}
  <!-- Class Screen -->
  <div class="min-h-screen bg-gray-50">
    <!-- Header -->
    <header class="bg-white border-b border-gray-200 px-6 py-4 shadow-sm">
      <div class="flex items-center justify-between max-w-7xl mx-auto">
        <div class="flex items-center gap-3">
          <div class="w-3 h-3 rounded-full {isConnected ? 'bg-green-500' : 'bg-red-500'}"></div>
          <h1 class="text-xl font-bold text-gray-800">ğŸ“ {studentName}ë‹˜ì˜ ìˆ˜ì—…</h1>
          {#if nodeInfo}
            {@const subNodeNum = nodeInfo.node_id?.match(/sub-(\d+)/)?.[1] || nodeInfo.node_name?.match(/sub-?(\d+)/i)?.[1] || null}
            <span class="text-xs px-2 py-1 rounded bg-blue-100 text-blue-800 font-mono" title="ë…¸ë“œ ID: {nodeInfo.node_id}">
              {#if nodeInfo.mode === 'sub'}
                {#if subNodeNum}
                  ì„œë¸Œ ë…¸ë“œ #{subNodeNum} ({nodeInfo.node_id})
                {:else}
                  ì„œë¸Œ ë…¸ë“œ: {nodeInfo.node_name} ({nodeInfo.node_id})
                {/if}
              {:else if nodeInfo.mode === 'main'}
                ë©”ì¸ ë…¸ë“œ: {nodeInfo.node_name}
              {:else}
                {nodeInfo.node_name} ({nodeInfo.mode})
              {/if}
            </span>
          {/if}
          {#if currentLatency > 0}
            <span class="text-xs px-2 py-1 rounded {currentLatency < 300 ? 'bg-green-100 text-green-800' : currentLatency < 1000 ? 'bg-yellow-100 text-yellow-800' : 'bg-red-100 text-red-800'}">
              {currentLatency}ms
            </span>
          {/if}
        </div>
        <button
          on:click={leaveClass}
          class="px-4 py-2 text-sm text-red-600 hover:bg-red-50 rounded-lg transition"
        >
          ë‚˜ê°€ê¸°
        </button>
      </div>
    </header>

    <main class="max-w-7xl mx-auto p-6">
      <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
        <!-- Teacher's Screen -->
        <div class="lg:col-span-2">
          <div class="bg-white rounded-lg shadow p-4">
            <h2 class="text-lg font-semibold mb-4 text-gray-800">ğŸ‘¨â€ğŸ« ì„ ìƒë‹˜ í™”ë©´ (WebRTC ì´ˆì €ì§€ì—°)</h2>
            <div class="bg-gray-900 rounded-lg aspect-video flex items-center justify-center overflow-hidden relative {videoContainerClass}">
              <!-- Video element with ultra-low latency settings - ALWAYS visible -->
              <!-- svelte-ignore a11y-media-has-caption -->
              <video
                bind:this={videoElement}
                class="video-stream"
                autoplay
                muted
                playsinline
                disablepictureinpicture
              ></video>
              
              <!-- Loading overlay - shows on top when video not loaded -->
              {#if !isVideoLoaded}
                <div class="absolute inset-0 flex items-center justify-center text-center text-gray-400 bg-gray-900 bg-opacity-90">
                  <div>
                    <div class="text-4xl mb-2">â³</div>
                    <p>ì„ ìƒë‹˜ í™”ë©´ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...</p>
                    <p class="text-sm mt-2">WebRTC ì—°ê²° ì¤‘</p>
                  </div>
                </div>
              {/if}
            </div>
          </div>
        </div>

        <!-- Chat Panel -->
        <div class="lg:col-span-1">
          <div class="bg-white rounded-lg shadow p-4 h-[calc(100vh-200px)] flex flex-col">
            <h2 class="text-lg font-semibold mb-4 text-gray-800">ğŸ’¬ ì§ˆë¬¸í•˜ê¸°</h2>
            
            <!-- Messages -->
            <div class="flex-1 overflow-y-auto space-y-3 mb-4">
              {#each messages as msg}
                <div class="p-3 rounded-lg {msg.sender === studentName ? 'bg-blue-100 ml-auto' : 'bg-gray-100'} max-w-[80%]">
                  <div class="text-xs text-gray-600 mb-1">
                    {msg.sender === 'teacher' ? 'ğŸ‘¨â€ğŸ« ì„ ìƒë‹˜' : msg.sender === studentName ? 'ë‚˜' : msg.sender}
                  </div>
                  <p class="text-sm text-gray-800">{msg.text}</p>
                </div>
              {/each}
            </div>

            <!-- Input -->
            <form on:submit|preventDefault={sendMessage} class="flex gap-2">
              <input
                type="text"
                bind:value={newMessage}
                placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."
                class="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
              />
              <button
                type="submit"
                class="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition"
              >
                ì „ì†¡
              </button>
            </form>
          </div>
        </div>
      </div>
    </main>
  </div>
{/if}
