"""
AIRClass Engagement Tracking Engine
í•™ìƒ ì°¸ì—¬ë„ ê³„ì‚° ë° ì¶”ì  ì‹œìŠ¤í…œ
"""

import logging
from typing import Optional, List, Dict, Tuple, Any
from datetime import datetime, timedelta, UTC
from models import StudentEngagement, EngagementMetrics, ActivityType

logger = logging.getLogger(__name__)


class EngagementCalculator:
    """í•™ìƒ ì°¸ì—¬ë„ ê³„ì‚° ì—”ì§„"""

    # ============================================
    # Score Configuration (0-100 scale)
    # ============================================

    # Attention Score ê³„ì‚° ê°€ì¤‘ì¹˜ (0-1)
    ATTENTION_WEIGHTS = {
        "quiz_participation": 0.4,  # í€´ì¦ˆ ì‘ë‹µ ì—¬ë¶€ (40%)
        "response_latency": 0.3,  # ë¹ ë¥¸ ì‘ë‹µ (30%)
        "screen_time": 0.3,  # í™”ë©´ ì‹œì²­ ì‹œê°„ (30%)
    }

    # Participation Score ê³„ì‚°
    PARTICIPATION_MULTIPLIER = 10  # 1 activity = 10 points, max 100

    # Quiz Accuracy (ì§ì ‘ ì ìˆ˜, 0-1 ì‚¬ì´)
    # ìë™ ê³„ì‚°: correct_responses / total_responses

    # Response Latency ê¸°ì¤€ (ë°€ë¦¬ì´ˆ)
    LATENCY_THRESHOLDS = {
        "excellent": (0, 1000),  # 0-1ì´ˆ: 1.0ì 
        "good": (1000, 3000),  # 1-3ì´ˆ: 0.8ì 
        "normal": (3000, 5000),  # 3-5ì´ˆ: 0.6ì 
        "slow": (5000, 10000),  # 5-10ì´ˆ: 0.4ì 
        "very_slow": (10000, float("inf")),  # 10ì´ˆ+: 0.2ì 
    }

    def __init__(self):
        """engagement calculator ì´ˆê¸°í™”"""
        logger.info("ğŸ“Š EngagementCalculator initialized")

    # ============================================
    # Main Calculation Methods
    # ============================================

    def calculate_attention_score(
        self,
        quiz_participation_rate: float,
        avg_response_latency_ms: int,
        screen_time_minutes: float,
        max_possible_time: float,
    ) -> float:
        """
        Attention Score ê³„ì‚° (0-1)

        Args:
            quiz_participation_rate: í€´ì¦ˆ ì‘ë‹µë¥  (0-1)
            avg_response_latency_ms: í‰ê·  ì‘ë‹µ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
            screen_time_minutes: ì´ ì‹œì²­ ì‹œê°„ (ë¶„)
            max_possible_time: ìµœëŒ€ ê°€ëŠ¥ ì‹œê°„ (ë¶„, ì˜ˆ: 50ë¶„ ìˆ˜ì—…)

        Returns:
            float: ì£¼ì˜ì§‘ì¤‘ë„ ì ìˆ˜ (0-1)
        """
        # 1. Quiz Participation ì ìˆ˜
        quiz_score = quiz_participation_rate  # 0-1

        # 2. Response Latency ì ìˆ˜
        latency_score = self._calculate_latency_score(avg_response_latency_ms)

        # 3. Screen Time ì ìˆ˜
        screen_time_score = min(screen_time_minutes / max_possible_time, 1.0)

        # ê°€ì¤‘í‰ê· 
        attention_score = (
            quiz_score * self.ATTENTION_WEIGHTS["quiz_participation"]
            + latency_score * self.ATTENTION_WEIGHTS["response_latency"]
            + screen_time_score * self.ATTENTION_WEIGHTS["screen_time"]
        )

        return min(max(attention_score, 0.0), 1.0)

    def _calculate_latency_score(self, latency_ms: int) -> float:
        """ì‘ë‹µ ì†ë„ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (0-1)"""
        for threshold, (min_ms, max_ms) in self.LATENCY_THRESHOLDS.items():
            if min_ms <= latency_ms <= max_ms:
                score_map = {
                    "excellent": 1.0,
                    "good": 0.8,
                    "normal": 0.6,
                    "slow": 0.4,
                    "very_slow": 0.2,
                }
                return score_map[threshold]
        return 0.0

    def calculate_participation_score(
        self,
        chat_message_count: int,
        quiz_response_count: int,
        session_duration_minutes: float,
    ) -> int:
        """
        Participation Score ê³„ì‚° (0-100)

        í™œë™ ê¸°ë°˜ ì ìˆ˜:
        - ì±„íŒ… ë©”ì‹œì§€ 1ê°œ = 5ì 
        - í€´ì¦ˆ ì‘ë‹µ 1ê°œ = 5ì 
        - ì„¸ì…˜ ì°¸ì„ = 10ì 

        Args:
            chat_message_count: ì±„íŒ… ë©”ì‹œì§€ ìˆ˜
            quiz_response_count: í€´ì¦ˆ ì‘ë‹µ ìˆ˜
            session_duration_minutes: ì„¸ì…˜ ì°¸ì„ ì‹œê°„

        Returns:
            int: ì°¸ì—¬ ì ìˆ˜ (0-100)
        """
        score = 0

        # ì„¸ì…˜ ì°¸ì„ ê¸°ë³¸ ì ìˆ˜
        if session_duration_minutes > 0:
            score += 10

        # ì±„íŒ… í™œë™ ì ìˆ˜ (ìµœëŒ€ 40ì )
        chat_score = min(chat_message_count * 5, 40)
        score += chat_score

        # í€´ì¦ˆ í™œë™ ì ìˆ˜ (ìµœëŒ€ 50ì )
        quiz_score = min(quiz_response_count * 5, 50)
        score += quiz_score

        return min(score, 100)

    def calculate_quiz_accuracy(
        self,
        correct_responses: int,
        total_responses: int,
    ) -> float:
        """
        Quiz Accuracy ê³„ì‚° (0-1)

        Args:
            correct_responses: ì •ë‹µ ê°œìˆ˜
            total_responses: ì´ ì‘ë‹µ ê°œìˆ˜

        Returns:
            float: ì •ë‹µë¥  (0-1)
        """
        if total_responses == 0:
            return 0.0
        return min(max(correct_responses / total_responses, 0.0), 1.0)

    def calculate_overall_engagement_score(
        self,
        attention_score: float,
        participation_score: int,
        quiz_accuracy: float,
    ) -> float:
        """
        ì´ ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° (0-100)

        ê°€ì¤‘í‰ê· :
        - Attention Score (40%)
        - Participation Score (40%)
        - Quiz Accuracy (20%)

        Args:
            attention_score: ì£¼ì˜ì§‘ì¤‘ë„ (0-1)
            participation_score: ì°¸ì—¬ ì ìˆ˜ (0-100)
            quiz_accuracy: ì •ë‹µë¥  (0-1)

        Returns:
            float: ì¢…í•© ì°¸ì—¬ë„ ì ìˆ˜ (0-100)
        """
        overall = (
            (attention_score * 100) * 0.4
            + participation_score * 0.4
            + (quiz_accuracy * 100) * 0.2
        )

        return min(max(overall, 0.0), 100.0)

    # ============================================
    # Confusion Detection
    # ============================================

    def detect_confusion(
        self,
        quiz_accuracy: float,
        chat_activity_high: bool,
        confusion_indicators: List[str],
    ) -> Tuple[bool, float]:
        """
        í˜¼ë™ë„ ê°ì§€ (í˜¼ë™ ìƒíƒœ ì—¬ë¶€ + í™•ì‹ ë„)

        í˜¼ë™ ì§€í‘œ:
        1. ë‚®ì€ ì •ë‹µë¥  (< 70%) - ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ í˜¼ë€ë„ ë†’ìŒ
        2. ë†’ì€ ì±„íŒ… í™œë™ - ì§ˆë¬¸ì´ ë§ìŒ
        3. ëª…ì‹œì  í˜¼ë™ ì§€í‘œ (ë°˜ë³µ ì§ˆë¬¸, ì‹¤ìˆ˜ íŒ¨í„´)

        Args:
            quiz_accuracy: ì •ë‹µë¥  (0-1)
            chat_activity_high: ì±„íŒ… í™œë™ ë§ìŒ ì—¬ë¶€
            confusion_indicators: í˜¼ë™ ì§€í‘œ ë¦¬ìŠ¤íŠ¸

        Returns:
            (bool, float): (í˜¼ë™ ìƒíƒœ ì—¬ë¶€, í™•ì‹ ë„ 0-1)
        """
        # ì§€í‘œÂ·ì±„íŒ… ì‹ í˜¸ê°€ ì „í˜€ ì—†ìœ¼ë©´ í˜¼ë™ ì—†ìŒìœ¼ë¡œ ê°„ì£¼ (ê¸°ë³¸ê°’ 0.0)
        if not confusion_indicators and not chat_activity_high:
            return False, 0.0

        confidence = 0.0

        # 1. Quiz accuracy factor (ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ í˜¼ë€ ê°€ëŠ¥ì„± ë†’ìŒ)
        # 70% ë¯¸ë§Œì¼ ë•Œ í˜¼ë€ ì‹ í˜¸ë¡œ íŒë‹¨
        if quiz_accuracy < 0.7:
            # 0% = 0.4 confidence, 70% = 0.0 confidence (ì„ í˜• ìŠ¤ì¼€ì¼)
            accuracy_factor = (0.7 - quiz_accuracy) / 0.7
            confidence += accuracy_factor * 0.4  # ìµœëŒ€ 0.4

        # 2. Chat activity factor (ì§ˆë¬¸ì´ ë§ìœ¼ë©´ í˜¼ë€ ì‹ í˜¸)
        if chat_activity_high:
            confidence += 0.3  # ì±„íŒ… í™œë™ ë†’ìœ¼ë©´ +0.3 (ê°•í•œ í˜¼ë€ ì‹ í˜¸)

        # 3. Explicit confusion indicators (ëª…ì‹œì  í˜¼ë™ íŒ¨í„´)
        if confusion_indicators:
            # ê° ì§€í‘œë‹¹ 0.1ì”© ì¶”ê°€ (ìµœëŒ€ 0.4)
            indicator_boost = min(len(confusion_indicators) * 0.1, 0.4)
            confidence += indicator_boost

        # Clamp confidence to [0, 1]
        confidence = min(max(confidence, 0.0), 1.0)

        # Decision threshold: > 0.5 = confused
        is_confused = confidence > 0.5

        return is_confused, confidence

    # ============================================
    # Engagement Trend Analysis
    # ============================================

    def analyze_trend(
        self,
        recent_scores: List[float],
        window_minutes: int = 10,
    ) -> Dict[str, Any]:
        """
        ì°¸ì—¬ë„ ì¶”ì„¸ ë¶„ì„ (ìµœê·¼ Në¶„ ê¸°ì¤€)

        Args:
            recent_scores: ìµœê·¼ ì°¸ì—¬ë„ ì ìˆ˜ë“¤ (ì‹œê°„ìˆœ)
            window_minutes: ë¶„ì„ ìœˆë„ìš° (ê¸°ë³¸ 10ë¶„)

        Returns:
            Dict: trend_direction, trend_strength ë“±
        """
        if len(recent_scores) < 2:
            return {
                "trend_direction": "stable",
                "trend_strength": 0.0,
                "average": recent_scores[-1] if recent_scores else 0.0,
            }

        # ì„ í˜• íšŒê·€ë¡œ ì¶”ì„¸ ê³„ì‚°
        first_half_avg = sum(recent_scores[: len(recent_scores) // 2]) / max(
            len(recent_scores) // 2, 1
        )
        second_half_avg = sum(recent_scores[len(recent_scores) // 2 :]) / max(
            len(recent_scores) - len(recent_scores) // 2, 1
        )

        trend_direction = (
            "increasing" if second_half_avg > first_half_avg else "decreasing"
        )
        trend_strength = abs(second_half_avg - first_half_avg) / 100.0

        return {
            "trend_direction": trend_direction,
            "trend_strength": min(trend_strength, 1.0),
            "average": sum(recent_scores) / len(recent_scores),
            "recent": recent_scores[-1],
            "previous": recent_scores[-2] if len(recent_scores) >= 2 else None,
        }

    # ============================================
    # Score Interpretation
    # ============================================

    @staticmethod
    def interpret_engagement_level(score: float) -> Dict[str, Any]:
        """
        ì°¸ì—¬ë„ ì ìˆ˜ í•´ì„

        Args:
            score: ì°¸ì—¬ë„ ì ìˆ˜ (0-100)

        Returns:
            Dict: level, description, recommendations
        """
        if score >= 80:
            return {
                "level": "excellent",
                "description": "í•™ìƒì´ ë§¤ìš° ë†’ì€ ì°¸ì—¬ë„ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤",
                "color": "green",
                "recommendations": ["ì§€ì†ì ì¸ ì°¸ì—¬ ìœ ì§€", "ì‹¬í™” í•™ìŠµ ì œê³µ ê³ ë ¤"],
            }
        elif score >= 60:
            return {
                "level": "good",
                "description": "í•™ìƒì´ ì–‘í˜¸í•œ ì°¸ì—¬ë„ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤",
                "color": "blue",
                "recommendations": ["í˜„ì¬ ìƒíƒœ ìœ ì§€", "ì¶”ê°€ ê³¼ì œ ì œì‹œ ê³ ë ¤"],
            }
        elif score >= 40:
            return {
                "level": "moderate",
                "description": "í•™ìƒì˜ ì°¸ì—¬ë„ê°€ ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤",
                "color": "yellow",
                "recommendations": ["ì°¸ì—¬ ë…ë ¤", "ê°œë… ì¬ì„¤ëª…", "ê°œë³„ í™•ì¸"],
            }
        else:
            return {
                "level": "low",
                "description": "í•™ìƒì˜ ì°¸ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤",
                "color": "red",
                "recommendations": ["ì¦‰ì‹œ ê°œì… í•„ìš”", "ì¼ëŒ€ì¼ ìƒë‹´", "ê³¼ì œ ì¬ì„¤ì •"],
            }


class EngagementTracker:
    """ì‹¤ì‹œê°„ í•™ìƒ ì°¸ì—¬ë„ ì¶”ì ê¸°"""

    def __init__(self, db_manager):
        """
        Args:
            db_manager: DatabaseManager ì¸ìŠ¤í„´ìŠ¤
        """
        self.db_manager = db_manager
        self.calculator = EngagementCalculator()
        self.engagement_cache: Dict[
            str, StudentEngagement
        ] = {}  # {session_id:student_id: engagement}

        logger.info("ğŸ“Š EngagementTracker initialized")

    async def track_activity(
        self,
        session_id: str,
        student_id: str,
        student_name: str,
        node_name: str,
        activity_type: ActivityType,
        activity_data: Dict,
    ) -> Optional[StudentEngagement]:
        """
        í•™ìƒ í™œë™ ê¸°ë¡ ë° ì°¸ì—¬ë„ ì—…ë°ì´íŠ¸

        Args:
            session_id: ì„¸ì…˜ ID
            student_id: í•™ìƒ ID
            student_name: í•™ìƒ ì´ë¦„
            node_name: ë…¸ë“œ ì´ë¦„
            activity_type: í™œë™ íƒ€ì… (CHAT, QUIZ_RESPONSE, PRESENCE)
            activity_data: í™œë™ ë°ì´í„° (ì˜ˆ: response_time_ms, is_correct ë“±)

        Returns:
            Optional[StudentEngagement]: ì—…ë°ì´íŠ¸ëœ ì°¸ì—¬ë„ ê°ì²´
        """
        try:
            # ê¸°ì¡´ ì°¸ì—¬ë„ ì¡°íšŒ
            cache_key = f"{session_id}:{student_id}"
            engagement = self.engagement_cache.get(cache_key)

            if not engagement:
                # DBì—ì„œ ì¡°íšŒ
                engagements = await self.db_manager.get_session_engagement(session_id)
                for eng in engagements:
                    if eng.student_id == student_id:
                        engagement = eng
                        break

            if not engagement:
                # ìƒˆ ì°¸ì—¬ë„ ê°ì²´ ìƒì„±
                engagement = StudentEngagement(
                    session_id=session_id,
                    student_id=student_id,
                    student_name=student_name,
                    node_name=node_name,
                    metrics=EngagementMetrics(),
                    updated_at=datetime.now(UTC),
                )

            # í™œë™ íƒ€ì…ë³„ ì²˜ë¦¬
            if activity_type == ActivityType.CHAT:
                engagement.metrics.chat_message_count += 1

            elif activity_type == ActivityType.QUIZ_RESPONSE:
                engagement.metrics.participation_count += 1
                if "response_time_ms" in activity_data:
                    # í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°
                    prev_latency = engagement.metrics.response_latency_ms
                    new_latency = activity_data["response_time_ms"]
                    engagement.metrics.response_latency_ms = int(
                        (prev_latency + new_latency) / 2
                    )

                if "is_correct" in activity_data:
                    # Quiz accuracy ì—…ë°ì´íŠ¸
                    if activity_data["is_correct"]:
                        correct_count = int(
                            engagement.metrics.quiz_accuracy
                            * engagement.metrics.participation_count
                        )
                        correct_count += 1
                    else:
                        correct_count = int(
                            engagement.metrics.quiz_accuracy
                            * (engagement.metrics.participation_count - 1)
                        )

                    engagement.metrics.quiz_accuracy = (
                        correct_count / engagement.metrics.participation_count
                        if engagement.metrics.participation_count > 0
                        else 0.0
                    )

            elif activity_type == ActivityType.PRESENCE:
                # Screen time ê¸°ë¡ (ë³„ë„ ì²˜ë¦¬)
                pass

            # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
            engagement.metrics.last_activity_time = datetime.now(UTC)
            engagement.updated_at = datetime.now(UTC)

            # ìºì‹œ ì—…ë°ì´íŠ¸
            self.engagement_cache[cache_key] = engagement

            # DB ì €ì¥
            await self.db_manager.update_student_engagement(engagement)

            logger.debug(
                f"âœ… Engagement tracked: {student_id} ({activity_type}) - score: {engagement.metrics.quiz_accuracy:.2f}"
            )

            return engagement

        except Exception as e:
            logger.error(f"âŒ Failed to track activity: {e}")
            return None

    async def calculate_session_engagement(
        self,
        session_id: str,
        session_duration_minutes: float,
    ) -> Dict[str, Any]:
        """
        ì„¸ì…˜ ì „ì²´ ì°¸ì—¬ë„ í†µê³„ ê³„ì‚°

        Args:
            session_id: ì„¸ì…˜ ID
            session_duration_minutes: ì„¸ì…˜ ì§„í–‰ ì‹œê°„

        Returns:
            Dict: ì„¸ì…˜ë³„ ì°¸ì—¬ë„ í†µê³„
        """
        try:
            engagements = await self.db_manager.get_session_engagement(session_id)

            if not engagements:
                return {
                    "session_id": session_id,
                    "total_students": 0,
                    "average_score": 0.0,
                    "students_by_level": {},
                }

            scores = []
            students_by_level = {"excellent": 0, "good": 0, "moderate": 0, "low": 0}

            for engagement in engagements:
                # ì¢…í•© ì ìˆ˜ ê³„ì‚°
                overall_score = self.calculator.calculate_overall_engagement_score(
                    attention_score=engagement.metrics.attention_score,
                    participation_score=self.calculator.calculate_participation_score(
                        engagement.metrics.chat_message_count,
                        engagement.metrics.participation_count,
                        session_duration_minutes,
                    ),
                    quiz_accuracy=engagement.metrics.quiz_accuracy,
                )

                scores.append(overall_score)

                # ë ˆë²¨ ë¶„ë¥˜
                interpretation = self.calculator.interpret_engagement_level(
                    overall_score
                )
                students_by_level[interpretation["level"]] += 1

            return {
                "session_id": session_id,
                "total_students": len(engagements),
                "average_score": sum(scores) / len(scores) if scores else 0.0,
                "max_score": max(scores) if scores else 0.0,
                "min_score": min(scores) if scores else 0.0,
                "students_by_level": students_by_level,
                "engagement_details": [
                    {
                        "student_id": eng.student_id,
                        "student_name": eng.student_name,
                        "score": scores[i],
                        "level": self.calculator.interpret_engagement_level(scores[i])[
                            "level"
                        ],
                    }
                    for i, eng in enumerate(engagements)
                ],
            }

        except Exception as e:
            logger.error(f"âŒ Failed to calculate session engagement: {e}")
            return {}

    async def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.engagement_cache.clear()
        logger.info("ğŸ§¹ Engagement cache cleared")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
engagement_tracker = None


async def init_engagement_tracker(db_manager) -> Optional[EngagementTracker]:
    """EngagementTracker ì´ˆê¸°í™”"""
    global engagement_tracker

    try:
        engagement_tracker = EngagementTracker(db_manager)
        logger.info("âœ… EngagementTracker initialized successfully")
        return engagement_tracker
    except Exception as e:
        logger.error(f"âŒ Failed to initialize EngagementTracker: {e}")
        engagement_tracker = None
        return None


def get_engagement_tracker() -> Optional[EngagementTracker]:
    """EngagementTracker ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return engagement_tracker
